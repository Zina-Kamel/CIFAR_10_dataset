{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10 dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e1ea19fd34c47b9adc88f4248211a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f0ce968871c4330b8fe3fac95454613",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad8d19bfb8ab475382ad586a62f53194",
              "IPY_MODEL_f0772cc306254fe19ab6a24a7749e762"
            ]
          }
        },
        "6f0ce968871c4330b8fe3fac95454613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad8d19bfb8ab475382ad586a62f53194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_107ab9dec2bb471ca55687fdd7548231",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1861d9e4976649e8961f09044060a8b9"
          }
        },
        "f0772cc306254fe19ab6a24a7749e762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b5efedec6bd4630aed413142be0c7c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:05&lt;00:00, 30595075.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f45322fdc7e14f4998472796bbae2ace"
          }
        },
        "107ab9dec2bb471ca55687fdd7548231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1861d9e4976649e8961f09044060a8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b5efedec6bd4630aed413142be0c7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f45322fdc7e14f4998472796bbae2ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0LLyoAKt7Wq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "6e1ea19fd34c47b9adc88f4248211a99",
            "6f0ce968871c4330b8fe3fac95454613",
            "ad8d19bfb8ab475382ad586a62f53194",
            "f0772cc306254fe19ab6a24a7749e762",
            "107ab9dec2bb471ca55687fdd7548231",
            "1861d9e4976649e8961f09044060a8b9",
            "3b5efedec6bd4630aed413142be0c7c5",
            "f45322fdc7e14f4998472796bbae2ace"
          ]
        },
        "id": "OhlZCld3IEw7",
        "outputId": "8a223b17-7287-4331-bcff-2096e378eba2"
      },
      "source": [
        "#getting mean and sd \n",
        "from torchvision import datasets,transforms as T\n",
        "\n",
        "#step1: load dataset with only ToTensor transform\n",
        "train_ds = datasets.CIFAR10('CIFAR10/', train = True, download = True, transform=T.ToTensor())\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e1ea19fd34c47b9adc88f4248211a99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting CIFAR10/cifar-10-python.tar.gz to CIFAR10/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr-8-qN_JAuf"
      },
      "source": [
        "#step2: append or collect all images in one empty list\n",
        "\n",
        "train_imgs = torch.stack([train_imgs_t for train_imgs_t,_ in train_ds], dim=3)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO9zTzANJyem",
        "outputId": "750ae6a0-dd91-409d-c851-78399301fb91"
      },
      "source": [
        "train_imgs.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32, 50000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKRBIOtYJ7jj",
        "outputId": "96b86f14-432e-4104-d18f-7b416297174a"
      },
      "source": [
        "# 3,32,32,5000 ---> 3,32*32*5000 --> mean\n",
        "\n",
        "train_imgs.view(3,-1).mean(dim=1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9HYNyyGKOEj",
        "outputId": "c8b07968-615e-49ef-ab93-d580e5323b86"
      },
      "source": [
        "# 3,32,32,5000 ---> 3,32*32*5000 --> std\n",
        "\n",
        "train_imgs.view(3,-1).std(dim=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_88Ts9d0oOV"
      },
      "source": [
        "#For CIFAR-10 Dataset Channel mean is 0.4914, 0.4822, 0.4465\n",
        "#Channel wise Standard Deviation is 0.2470, 0.2435, 0.2616\n",
        "\n",
        "\n",
        "transform = T.Compose([\n",
        "      T.ToTensor(),\n",
        "      T.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)) #since we have colored data so 3 channels mean 3 values \n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA7gXo_dHxVZ",
        "outputId": "4f17a04c-3c12-40bd-b1ef-9e56fc26b9f2"
      },
      "source": [
        "train_ds = datasets.CIFAR10('CIFAR10/', train = True, download = True, transform= transform)\n",
        "test_ds = datasets.CIFAR10('CIFAR10/', train = False, download = True, transform= transform)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BIcFuApK7FA",
        "outputId": "e2819c12-e46a-4f8d-d282-f4e884adcb18"
      },
      "source": [
        "print(\"size of training dataset is {}\".format(len(train_ds)))\n",
        "print(\"size of test dataset is {}\".format(len(test_ds)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of training dataset is 50000\n",
            "size of test dataset is 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lC9f0684Ect"
      },
      "source": [
        "Plot examples from the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVzNw0Kd6P7U"
      },
      "source": [
        "#changing labels from numbers to their relative descriptions \n",
        "\n",
        "labels = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "Zz2iSwuF4IzR",
        "outputId": "f36822af-ad2a-4555-a518-1912d5fb06e2"
      },
      "source": [
        "index = 99\n",
        "image,label = train_ds[index]\n",
        "\n",
        "image = image.permute(1,2,0) #change the image shape from C,H,W to H,W,C for plotting purposes. The axis of the channel is 0 and it changed from being on teh right to the left \n",
        "\n",
        "print(image.shape)\n",
        "\n",
        "#if you want to plot the original image (not normalised), you apply image * std + mean\n",
        "\n",
        "#image = image * torch.Tensor([0.2470, 0.2435, 0.2616]) + torch.Tensor([0.4914, 0.4822, 0.4465]) \n",
        "\n",
        "#we can see that the normalised image has black area as normalisation shifted the rgb levels above 0 to 1 range \n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title(labels[label]);"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 32, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARYElEQVR4nO3df7BU5X3H8fcnCIJCAoqSW0DxB47SasChjFZN1Uyt0qbo2PqjjaMzNqSZmOqMaeuYaTE2bWMm6jjVMUVhQhIjWkVx1GlCrR1jp2quioDSCFFQKT9EJRpTf4Df/rGH8cLsc+69u2fPXng+r5k7d/d59pzz9cjn7tlz9jyPIgIz2/t9otsFmFk9HHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu7VF0j7drsEGxmHPnKTJkpZIel3SG5JulnSEpP8onm+VdIeksX2WWSfpbyStAN514PcMDnvGJA0DHgTWA1OAicBiQMA/Ab8BHANMBq7ZbfELgT8AxkbE9noqtnbI343Pl6QTgQeAnrLASjobmBcRM4rn64BrI2JhLYVaJXz4lbfJwPrdgy5pAnATcAowhsYR4Fu7LftqLRVaZXwYn7dXgUOafOb+RyCAYyPik8AXaBza9+VDwj2Mw563p4CNwLck7S9ppKSTaLyb/wr4paSJwF91s0irhsOesYjYAXweOBJ4BXgNOB/4BnA88EvgIWBJt2q06vgEnVkm/M5ulgmH3SwTDrtZJhx2s0zU+qUaST4bmInxo4Y3bd/6fx/WXElzhx+y+9cGPvbuB+l/pps3pdc5amy678CSvhEjm7eP2S+9zIv/07z9g/dh+/Zo+h/XVtglnUnjm1bDgNsj4lvtrM/2HnOOPLhp+4KVG2qupLlvX71vsu+JV99L9n3nH9LrPOr0dN9Ff5Tum3RM8/bTZqSXOeOk5u0vPp9epuXD+OImiluAs4BpwIWSprW6PjPrrHY+s88C1kbESxHxAY27peZUU5aZVa2dsE9k15shXivadiFprqReSb1tbMvM2tTxE3QRMR+YDz5BZ9ZN7byzb6Bxi+ROk4o2MxuC2nln/xkwVdJhNEJ+AfCnlVRle7yhctZ9RKJ96qTrksucO/f4ZN+jj52S7Dur5Iz7b5+Y7lv9WvP2Z1enl5mSOIO/7qX0Mi2HPSK2S7oM+DGNS28LI6LkxL+ZdVNbn9kj4mHg4YpqMbMO8tdlzTLhsJtlwmE3y4TDbpaJWoel8pdqbE/3FyUXl98pubMtcWMbAGN6EusrmXpjwS2Jjm0QHza/683v7GaZcNjNMuGwm2XCYTfLhMNulglP7Gg2CM+uTPelbk4BeOLldN/La5q3/7qskG1lnc35nd0sEw67WSYcdrNMOOxmmXDYzTLhsJtlwjfCmO1lInwjjFnWHHazTDjsZplw2M0y4bCbZcJhN8uEw26WibZucZW0DngH2AFsj4iZVRRlZtWr4n720yJiawXrMbMO8mG8WSbaDXsAP5H0tKS5zV4gaa6kXkm9bW7LzNrQ1nfjJU2MiA2SDgaWAV+NiMdKXu/vxpt1WEe+Gx8RG4rfW4D7gFntrM/MOqflsEvaX9KYnY+BM4BVVRVmZtVq52z8BOA+STvX86OI+LdKqjKzyvl+drO9jO9nN8ucw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8tEv2GXtFDSFkmr+rQdIGmZpDXF73GdLdPM2jWQd/bvAWfu1nYV8EhETAUeKZ6b2RDWb9iL+dbf3K15DrCoeLwIOLviusysYq3O4johIjYWjzfRmNG1KUlzgbktbsfMKtLOlM0ARESUzc4aEfOB+eBZXM26qdWz8Zsl9QAUv7dUV5KZdUKrYX8AuLh4fDGwtJpyzKxTFFF+ZC3pTuBUYDywGZgH3A/cDRwCrAfOi4jdT+I1W5cP4806LCLUrL3fsFfJYTfrvFTY/Q06s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMtH2/ey2Z5hT0udbFvPgd3azTDjsZplw2M0y4bCbZcJhN8uEz8bvZb6ZaP/6f12eXGb8STcl+95osx4bOvzObpYJh90sEw67WSYcdrNMOOxmmXDYzTLhSSIycU9J37kz0n13PZvuO3/2gck+PeyLdt3S8iQRkhZK2iJpVZ+2ayRtkLS8+JldZbFmVr2BHMZ/DzizSfuNETG9+Hm42rLMrGr9hj0iHgP6nbTRzIa2dk7QXSZpRXGYPy71IklzJfVK6m1jW2bWplbDfitwBDAd2Ahcn3phRMyPiJkRMbPFbZlZBVoKe0RsjogdEfERcBswq9qyzKxqLd31JqknIjYWT88BVpW93uqz+MEVTduXL/yX5DLnLLkl2fdEybb+pOTy2v3jm7efvbVkhSXmHDsx2bd05YbWVpqZfsMu6U7gVGC8pNeAecCpkqYDAawDvtTBGs2sAv2GPSIubNK8oAO1mFkH+euyZplw2M0y4bCbZcJhN8uE73rby7T0/3PRfya7dMlpyb4RJat8//ZLm7b/7Z+nz+2mBssEWH/7tcm+v7xjcbJv6aMvlKx18CaU9I0t6ft5pVWUa/muNzPbOzjsZplw2M0y4bCbZcJhN8uEw26WCV96q0DZf9SUkr71FddRJv733XTn1/462XX0j9J3xJVdTnow0X5fyTLvlfTdWdL3UUnfxEnN2xdsSy/z+8ekLzdCyX6ceni67+WSATj/e1nJ9gZnJtDrS29meXPYzTLhsJtlwmE3y4TDbpYJn43fTdUFlt2G8ZsVb6vMzadMS/bt89N0laeVnJg+6qFXSra4f6I9PV6c9juuZH1pBybOuAN8dXvzW1fmTS65peWH6SsQHHXyAKsahDOaDQYFLEvf4JPis/Fm5rCb5cJhN8uEw26WCYfdLBMOu1km+r30Jmky8H0aw28FMD8ibpJ0AHAXjXs91gHnRcRb/axrSFx6GxJFAF8u6ftubVWUj6u2qXTJsjlGtrdUi7Wn3Utv24ErI2IacALwFUnTgKuARyJiKvBI8dzMhqh+wx4RGyPimeLxO8BqYCIwB1hUvGwRcHanijSz9g3qM7ukKcAM4ElgQp+ZXDdRfjRoZl024CmbJY0G7gWuiIi3pY8/FkREpD6PS5oLzG23UDNrz4De2SUNpxH0OyJiSdG8WVJP0d8DbGm2bETMj4iZETGzioLNrDX9hl2Nt/AFwOqIuKFP1wPAxcXji4Gl1ZdnZlUZyKW3k4GfAiv5eLivq2l8br8bOITGcGrnRcSb/ayr0qteJ5X0PV7lhqwenz4l3XfM8SV9h6T7xiVOJb21Ob3MqJJPt7M/n+4bmbrTDxh/cLovtbkjRqWXSYzYV3bprd/P7BHxONB0YeBz/S1vZkODv0FnlgmH3SwTDrtZJhx2s0w47GaZqHXAyRFSpC5AjC9Z7leJ9rVt1lOPkgsex3wp3Vc20mPZYIkvJwZ0XFIyeOHW+9N9pQ4t6Utd2iqb5GlP96l016d/J9135R82b19TMtXUmuaTb83sXUrv2697wEmznDnsZplw2M0y4bCbZcJhN8uEw26WiVovvR0kxZxE3+SS5Y5OtJ/fZj212GdWum/7U/XVYVnwXG9m5rCb5cJhN8uEw26WCYfdLBO1no0fK8Wpib6yyYIe7EAtZkPF9ET7cy2uL3w23ixvDrtZJhx2s0w47GaZcNjNMuGwm2Wi3xlhJE0Gvk9jSuYA5kfETZKuAb4IvF689OqIeLhsXZ8EUiOrbRtoxV3060T7qpJlynZwyYRGtpe5oKSv1UtsgzWQKZu3A1dGxDOSxgBPS1pW9N0YEd/pXHlmVpWBzPW2EdhYPH5H0mpgYqcLM7NqDeozu6QpwAwaM7gCXCZphaSFksZVXJuZVWjAYZc0GrgXuCIi3gZuBY6g8W2/jcD1ieXmSuqV1Jsa/93MOm9AYZc0nEbQ74iIJQARsTkidkTER8BtQNMhWSJifkTMjIiZo6uq2swGrd+wSxKwAFgdETf0ae/p87JzKD8pbWZdNpCz8ScBFwErJS0v2q4GLpQ0ncbluHVAyVxGDSP2gSmJeZ7GbRpAJTVoervQEFPffYpWlbtaWObPZpyd7Dv22ObnyP/5obuTywzkbPzjNM9A6TV1Mxta/A06s0w47GaZcNjNMuGwm2XCYTfLRK0DTh4qxdWJvn6v21VoUUnfJRVvq+yv6UctrrPsLqnjWlynte+Vkr5DK97Wfon294AdHnDSLG8Ou1kmHHazTDjsZplw2M0y4bCbZWIgd71VZtg+MDpx19tNJXe9XV5xHZdUvL4yrV5eK/OZkj7fEdc9t9a4rdTgp2X8zm6WCYfdLBMOu1kmHHazTDjsZplw2M0yUeult+HDoaened8PSi69/X2i/Y22K6rGuSV9ZTu4lUEIbejaWPH6frek771Ee9kQz35nN8uEw26WCYfdLBMOu1kmHHazTPR7Nl7SSOAxYN/i9fdExDxJhwGLgQOBp4GLIuKDsnWN2u8T/NaxzUfPmvRseo7XH/dXZJd98ebFyb5VSx9M9t217IeV1/KpRPvblW/JOq1sRrQpI5u3D3s/vcxA3tnfB06PiM/QmJ75TEknANcBN0bEkcBbwKUDWJeZdUm/YY+GnW+7w4ufAE4H7inaFwHpWejMrOsGOj/7sGIG1y3AMuAXwLaI2F685DWg+bSSZjYkDCjsEbEjIqYDk4BZwNED3YCkuZJ6JfW+8Z6HVjDrlkGdjY+IbcCjwInAWEk7T/BNAjYklpkfETMjYuaBI/eE2c/N9k79hl3SQZLGFo9HAb8HrKYR+j8uXnYxsLRTRZpZ+wZyI0wPsEjSMBp/HO6OiAclvQAslvRN4FlgQb8bm3AQB1/5haZ91x50X3K5Vde/1LT9yX5Lr8e8b6Uvvc04rt4JmXyJbe+xtaTvunn3N21fe/OVyWX6DXtErABmNGl/icbndzPbA/gbdGaZcNjNMuGwm2XCYTfLhMNulglF1PetNkmvA+uLp+Mpv7pQF9exK9exqz2tjkMj4qBmHbWGfZcNS70RMbMrG3cdriPDOnwYb5YJh90sE90M+/wubrsv17Er17GrvaaOrn1mN7N6+TDeLBMOu1kmuhJ2SWdK+rmktZKu6kYNRR3rJK2UtFxSb43bXShpi6RVfdoOkLRM0pri97gu1XGNpA3FPlkuaXYNdUyW9KikFyQ9L+nyor3WfVJSR637RNJISU9Jeq6o4xtF+2GSnixyc5ekEYNacUTU+gMMozGG3eHACOA5YFrddRS1rAPGd2G7nwWOB1b1afs2cFXx+Crgui7VcQ3wtZr3Rw9wfPF4DPAiMK3ufVJSR637BBAwung8nMbQDScAdwMXFO3fBb48mPV24519FrA2Il6Kxjjzi4E5XaijayLiMeDN3Zrn0BilF2oarTdRR+0iYmNEPFM8fofGSEgTqXmflNRRq2iofETnboR9IvBqn+fdHJk2gJ9IelrS3C7VsNOEiNg56+8mYEIXa7lM0oriML/jHyf6kjSFxmApT9LFfbJbHVDzPunEiM65n6A7OSKOB84CviLps90uCBp/2Wn8IeqGW4EjaEwIshG4vq4NSxoN3AtcERG7jLBV5z5pUkft+yTaGNE5pRth3wBM7vM8OTJtp0XEhuL3FuA+ujvM1mZJPQDF7y3dKCIiNhf/0D4CbqOmfSJpOI2A3RERS4rm2vdJszq6tU+KbQ96ROeUboT9Z8DU4sziCOAC4IG6i5C0v6QxOx8DZwCrypfqqAdojNILXRytd2e4CudQwz6RJBoDlq6OiBv6dNW6T1J11L1POjaic11nGHc72zibxpnOXwBf71INh9O4EvAc8HyddQB30jgc/JDGZ69LaUyQ+QiwBvh34IAu1fEDYCWwgkbYemqo42Qah+grgOXFz+y690lJHbXuE+A4GiM2r6Dxh+Xv+vybfQpYC/wrsO9g1uuvy5plIvcTdGbZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJv4fLnJijk97VL0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J_VgOQH-HWN"
      },
      "source": [
        "Load dataset into batches\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLy07zQ8-NHO"
      },
      "source": [
        "from torch.utils.data import DataLoader, random_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8rt-YHiKjgj"
      },
      "source": [
        "train_dataset, valid_dataset = random_split(train_ds, (45000,5000))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCijS5NxK0Tr"
      },
      "source": [
        "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "validloader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(test_ds, batch_size=64, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t2onHJYLIoN",
        "outputId": "eb09efeb-d8ce-42bd-cd45-c1d6e43bc530"
      },
      "source": [
        "print(\"Total batches created in trainloader is {}\".format(len(trainloader)))\n",
        "print(\"Total batches created in trainloader is {}\".format(len(validloader)))\n",
        "print(\"Total batches created in trainloader is {}\".format(len(testloader)))\n",
        "\n",
        "print(\"Size of train dataset is {}\".format(len(trainloader.dataset)))\n",
        "print(\"Size of valid dataset is {}\".format(len(validloader.dataset)))\n",
        "print(\"Size of test dataset is {}\".format(len(testloader.dataset)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total batches created in trainloader is 704\n",
            "Total batches created in trainloader is 79\n",
            "Total batches created in trainloader is 157\n",
            "Size of train dataset is 45000\n",
            "Size of valid dataset is 5000\n",
            "Size of test dataset is 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP6Uph-gL2RL",
        "outputId": "c433b0da-467e-411a-fcdc-6409baa96755"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 32, 32])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv852R7bGYAT"
      },
      "source": [
        "Create CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7ZLgbzdEIiG"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqooFDurSSma"
      },
      "source": [
        "\n",
        "k : kernel_size or filters \n",
        "<br>\n",
        "p : padding \n",
        "<br>\n",
        "s : stride \n",
        "<br>\n",
        "W : Width \n",
        "<br>\n",
        "H : Height \n",
        "\n",
        "\\begin{equation*}\n",
        "For Same padding = \\frac{k - 1}{2} \\\\\n",
        "\\end{equation*}\n",
        "\n",
        "\\begin{equation*}\n",
        "W[next] = \\frac{W[previous] + 2p - k}{s} + 1 \\\\\n",
        "\\end{equation*}\n",
        "\n",
        "\\begin{equation*}\n",
        "H[next] = \\frac{H[previous] + 2p - k}{s} + 1 \\\\\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGl1r6xCd3T6"
      },
      "source": [
        "'''\n",
        "3 x 32 x 32 (input)\n",
        "\n",
        "       | k = (3,3), p = 1, s = 1 , out_channels = 16,operation = convolutional  #conv1\n",
        "       V activation = relu \n",
        "       \n",
        "16 x 32 x 32\n",
        "\n",
        "       | k = (2,2), s = 2, operation = Max Pooling #maxpool\n",
        "       V \n",
        "       \n",
        "16 x 15 x 15\n",
        "\n",
        "       | k = (3,3), p = 1, s = 1, out_channels = 32, operation = convolutional #conv2\n",
        "       V activation = relu\n",
        "       \n",
        "32 x 15 x 15 \n",
        "\n",
        "       | k = (2,2), s = 2, operation = Max Pooling #maxpool\n",
        "       V \n",
        "       \n",
        "32 x 8 x 8\n",
        "\n",
        "       | k = (3,3), p = 1 , s = 1 , out_channels = 64, operation = convolutional #conv3\n",
        "       V activation = relu \n",
        "       \n",
        "64 x 8 x 8\n",
        "\n",
        "       | k = (2,2), s = 2 , operation = MaxPooling #maxpool\n",
        "       V\n",
        "\n",
        "64 x 4 x  4\n",
        "    \n",
        "       |  operation = Flatten\n",
        "       V\n",
        "500\n",
        "\n",
        "       |  linear,activation = relu #linear1\n",
        "       V\n",
        "\n",
        "128\n",
        "       |  linear,activation = relu #linear2\n",
        "       V\n",
        "\n",
        "10  linear, activation = log_softmax #linear3\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO_Mdhv8uhLh"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR8eMbCWboBR"
      },
      "source": [
        "#in the init method you will define the layers and in the forward method you will use them to create the layer\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyModel,self).__init__()\n",
        "\n",
        "    self.conv_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3,3),padding=1,stride=1)\n",
        "    self.conv_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3),padding=1,stride=1)\n",
        "    self.conv_3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3),padding=1,stride=1)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
        "\n",
        "    self.linear_1 = nn.Linear(in_features=1024,out_features=500) #first fully connected layer\n",
        "    self.linear_2 = nn.Linear(in_features=500,out_features=128)\n",
        "    self.linear_3 = nn.Linear(in_features=128,out_features=10)\n",
        "\n",
        "\n",
        "  def forward(self,images):\n",
        "    a1 = self.maxpool(F.relu(self.conv_1(images)))\n",
        "    a2 = self.maxpool(F.relu(self.conv_2(a1)))\n",
        "    a3 = self.maxpool(F.relu(self.conv_3(a2)))\n",
        "    a3 = a3.view(a3.shape[0],-1) #change shape from 64,4,4 to 64*4*4\n",
        "    a4 = F.relu(self.linear_1(a3))\n",
        "    a5 = F.relu(self.linear_2(a4))\n",
        "    a6 = F.log_softmax(self.linear_3(a5),dim=1) #we will use log softmax becasue the loss function we will use take the log\n",
        "\n",
        "    return a6\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fc06fd-uysX",
        "outputId": "b5e70ba9-6ecf-40f9-c651-e3500ac3c492"
      },
      "source": [
        "model = MyModel()\n",
        "model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (conv_1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (maxpool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (linear_1): Linear(in_features=1024, out_features=500, bias=True)\n",
              "  (linear_2): Linear(in_features=500, out_features=128, bias=True)\n",
              "  (linear_3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzLlQT5Pv5UY"
      },
      "source": [
        "from torchsummary import summary\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVNV8maRwRju",
        "outputId": "2306fe75-f7d7-407c-d491-478fd9fd7da8"
      },
      "source": [
        "summary(model, input_size = (3,32,32))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
            "            Conv2d-3           [-1, 32, 16, 16]           4,640\n",
            "         MaxPool2d-4             [-1, 32, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          18,496\n",
            "         MaxPool2d-6             [-1, 64, 4, 4]               0\n",
            "            Linear-7                  [-1, 500]         512,500\n",
            "            Linear-8                  [-1, 128]          64,128\n",
            "            Linear-9                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 601,502\n",
            "Trainable params: 601,502\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.28\n",
            "Params size (MB): 2.29\n",
            "Estimated Total Size (MB): 2.58\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HUmGmwKsa9H"
      },
      "source": [
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "def view_classify(img, ps):\n",
        "\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze(),cmap = 'gray')\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return None"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml8o6zuhtzD5"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA72dQPmwsp8"
      },
      "source": [
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "criterion = nn.NLLLoss() #(logps, true_labels) that's why we applied log softmax layer instead of softmax layer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "epochs = 10"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ShYfa9H-XgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847a42cc-f6df-4a8a-ad67-dfff2e2fc9e7"
      },
      "source": [
        "for i in range(epochs):\n",
        "\n",
        "  train_loss = 0.0\n",
        "  train_acc = 0.0\n",
        "  valid_loss = 0.0\n",
        "  valid_acc = 0.0\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  for images,labels in tqdm(trainloader):\n",
        "\n",
        "    logps = model(images) #output ps\n",
        "\n",
        "    loss = criterion(logps,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() #dw,db\n",
        "    optimizer.step() #w=w-lr*dw\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    ps = torch.exp(logps) #log_softmax --> softmax\n",
        "    train_acc += multiclass_accuracy(ps,labels)\n",
        "\n",
        "  model.eval() #dropout, batch norm\n",
        "\n",
        "  for images,labels in tqdm(validloader):\n",
        "\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps,labels)\n",
        "\n",
        "    valid_loss += loss.item()\n",
        "    ps = torch.exp(logps) #log_softmax --> softmax\n",
        "    valid_acc += multiclass_accuracy(ps,labels)\n",
        "\n",
        "  avg_train_loss = train_loss/len(trainloader)\n",
        "  avg_valid_loss = valid_loss/len(validloader)\n",
        "  avg_train_acc = train_loss/len(trainloader)\n",
        "  avg_valid_acc = valid_loss/len(validloader)\n",
        "\n",
        "  print(\"Epoch: {} Train loss: {:.4f} Train accuracy: {:.4f}\".format(i,avg_train_loss,avg_train_acc))\n",
        "  print(\"Epoch: {} Valid loss: {:.4f} Valid accuracy: {:.4f}\".format(i,avg_valid_loss,avg_valid_acc))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [00:52<00:00, 13.32it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 25.04it/s]\n",
            "  0%|          | 2/704 [00:00<00:56, 12.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 1.4427 Train accuracy: 1.4427\n",
            "Epoch: 0 Valid loss: 1.2182 Valid accuracy: 1.2182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [00:56<00:00, 12.38it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 25.51it/s]\n",
            "  0%|          | 2/704 [00:00<00:57, 12.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Train loss: 1.0464 Train accuracy: 1.0464\n",
            "Epoch: 1 Valid loss: 0.9939 Valid accuracy: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [00:57<00:00, 12.18it/s]\n",
            "100%|██████████| 79/79 [00:02<00:00, 26.58it/s]\n",
            "  0%|          | 2/704 [00:00<00:57, 12.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2 Train loss: 0.8824 Train accuracy: 0.8824\n",
            "Epoch: 2 Valid loss: 0.9165 Valid accuracy: 0.9165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [01:00<00:00, 11.64it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 25.35it/s]\n",
            "  0%|          | 2/704 [00:00<01:04, 10.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3 Train loss: 0.7774 Train accuracy: 0.7774\n",
            "Epoch: 3 Valid loss: 0.8766 Valid accuracy: 0.8766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [01:00<00:00, 11.62it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 23.24it/s]\n",
            "  0%|          | 2/704 [00:00<00:57, 12.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4 Train loss: 0.6867 Train accuracy: 0.6867\n",
            "Epoch: 4 Valid loss: 0.8656 Valid accuracy: 0.8656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [00:57<00:00, 12.22it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 25.51it/s]\n",
            "  0%|          | 2/704 [00:00<00:56, 12.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5 Train loss: 0.6266 Train accuracy: 0.6266\n",
            "Epoch: 5 Valid loss: 0.9208 Valid accuracy: 0.9208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [00:56<00:00, 12.39it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 25.42it/s]\n",
            "  0%|          | 2/704 [00:00<00:57, 12.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6 Train loss: 0.5545 Train accuracy: 0.5545\n",
            "Epoch: 6 Valid loss: 0.9315 Valid accuracy: 0.9315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [00:56<00:00, 12.35it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 25.79it/s]\n",
            "  0%|          | 2/704 [00:00<00:56, 12.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7 Train loss: 0.5119 Train accuracy: 0.5119\n",
            "Epoch: 7 Valid loss: 0.9180 Valid accuracy: 0.9180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [00:56<00:00, 12.36it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 25.53it/s]\n",
            "  0%|          | 2/704 [00:00<00:55, 12.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8 Train loss: 0.4637 Train accuracy: 0.4637\n",
            "Epoch: 8 Valid loss: 0.9762 Valid accuracy: 0.9762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 704/704 [00:57<00:00, 12.33it/s]\n",
            "100%|██████████| 79/79 [00:03<00:00, 25.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9 Train loss: 0.4206 Train accuracy: 0.4206\n",
            "Epoch: 9 Valid loss: 1.0430 Valid accuracy: 1.0430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ZUGlAdEjtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b24ae0-d8ee-4085-b4d0-7f1c628949bb"
      },
      "source": [
        "test_loss = 0.0\n",
        "test_acc = 0.0\n",
        "\n",
        "model.eval() #turn off dropout and batch norm is we used them\n",
        "\n",
        "for images,labels in tqdm(testloader):\n",
        "\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps,labels)\n",
        "\n",
        "    test_loss += loss.item()\n",
        "    ps = torch.exp(logps) #log_softmax --> softmax\n",
        "    test_acc += multiclass_accuracy(ps,labels)\n",
        "\n",
        "avg_test_loss = test_loss/len(testloader)\n",
        "avg_test_acc = test_loss/len(testloader)\n",
        "\n",
        "print(\"Epoch: {} Test loss: {:.4f} Test accuracy: {:.4f}\".format(i,avg_test_loss,avg_test_acc))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:06<00:00, 25.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9 Test loss: 1.0716 Test accuracy: 1.0716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgl919DUFQdZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "674b48b6-5e2b-44f2-f65c-5207fe012e70"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "\n",
        "images,labels = dataiter.next()\n",
        "\n",
        "index = 3\n",
        "logps = model(images[index].unsqueeze(0)) #(3,32,32) --> (1,3,32,32)\n",
        "ps = torch.exp(logps)\n",
        "\n",
        "view_classify(images[index],ps)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}